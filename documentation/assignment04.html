<!doctype html>
<html lang="zh-CN">

<head>
    <meta charset="utf-8" />
    <link href="https://fonts.googleapis.com/css2?family=Codystar:wght@300;400&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Assignment 04 · Creative Technology 03</title>
    <link rel="stylesheet" href="css/style.css" />
</head>

<body>
    <div class="wrap">
        <header>
            <div class="title">
                <h1>ASSIGNMENT 04</h1>
                <p class="subtitle">#Text as material and artifact project</p>
            </div>

            <div class="meta">
                <div class="pill">Fall 2025 · MDP</div>
                <div class="pill"><span id="studentName">Yiqi Zhang</span></div>
            </div>
        </header>

        <div class="docLayout">
            <!-- Left: TOC -->
            <aside class="sidebar" aria-label="Table of contents">
                <ul class="toc">
                    <li><a href="#overview"><span>Overview</span><small>00</small></a></li>
                    <li><a href="#concept"><span>Concept</span><small>01</small></a></li>
                    <li><a href="#process"><span>Process</span><small>02</small></a></li>
                    <li><a href="#result"><span>Result</span><small>03</small></a></li>
                    <li><a href="homepage.html"><span>← Back Home</span><small>↩</small></a></li>
                </ul>
            </aside>

            <!-- Right: Documentation -->
            <main class="main" aria-label="Documentation content">

                <!-- Overview -->
                <section class="section" id="overview">
                    <h2 class="h2">Overview</h2>
                    <p class="p">
                        This project explores text as both source material and generative output within digital media
                        systems. Using the Quoteslate public API as a textual dataset, the website retrieves quotes
                        through a randomized request process and extracts key linguistic elements such as authorship,
                        tone, and structure. These fragments are then recombined through a custom algorithm to generate
                        new, machine-constructed sentences. Rather than imitating human authorship directly, the system
                        exposes the intermediate logic of language generation—selection, fragmentation, and
                        recombination—tracing a simplified pathway similar to that used by contemporary language models.
                        Through this process, the project frames text generation as a visible, procedural act, allowing
                        the machine to develop a distinct “voice” shaped by randomness, constraints, and algorithmic
                        decision-making rather than semantic understanding alone.
                    </p>

                </section>

                <!-- Concept -->
                <section class="section" id="concept">
                    <h2 class="h2">Concept</h2>
                    <figure class="figure">
                        <img src="04/poetrydb.png" alt="System diagram">
                    </figure>

                    <p class="p">
                        This project explores text as both source material and generative output within digital media
                        systems. The process began with a close study of a structured literary dataset from the PoetryDB
                        API, using the endpoint for Emily Dickinson’s poetry. By examining how poems are stored,
                        retrieved,
                        and formatted as data—titles, authorship, and lines—the project establishes a foundational
                        understanding of how human-authored language can be abstracted into machine-readable structures.
                        <br><br>
                        Building on this foundation, the project shifts toward a more dynamic text source: the
                        Quoteslate public API. Quotes are retrieved through randomized requests and treated as
                        linguistic fragments rather than complete, authoritative statements. These fragments are
                        extracted, reorganized, and recombined through a rule-based algorithm to produce new
                        machine-generated sentences.
                        <br><br>
                        Rather than simulating human intelligence or semantic comprehension, the system exposes a
                        simplified outline of how contemporary language-generation models operate—through selection,
                        randomness, recombination, and constraint. Authorship becomes distributed between the original
                        writers and the algorithm itself. The resulting text occupies a space between citation and
                        invention, speaking in a distinct non-human voice shaped by procedural logic rather than
                        meaning.
                    </p>
                </section>

                <!-- Process -->
                <section class="section" id="process">
                    <h2 class="h2">Process</h2>

                    <figure class="figure">
                        <img src="04/vite1.png" alt="System diagram">
                    </figure>

                    <p class="p">
                        While working in the terminal, I frequently encountered issues caused by small syntax errors,
                        such as extra spaces or missing slashes in file paths. These mistakes often prevented the Vite
                        server from running, even though the project files themselves were correct. This experience
                        underscored how command-line systems rely on strict syntax and do not interpret intent—each
                        character must be precise for the system to function as expected.
                    </p>

                    <figure class="figure">
                        <img src="04/vite2.png" alt="System diagram">
                    </figure>

                    <p class="p">
                        The project runs on a local Vite development server. Rather than opening a static HTML file, the
                        system must be launched from the project directory in the terminal. This step initiates a local
                        server that interprets the project’s structure, enables modular JavaScript, and allows API-based
                        data retrieval. The browser then accesses the running system via a local address, treating the
                        webpage as a live process rather than a static file.
                    </p>

                    <figure class="figure">
                        <img src="04/quoteslate.png" alt="System diagram">
                    </figure>

                    <p class="p">

                        The project initially began with an interest in film and television dialogue. I was drawn to the
                        poetic quality of spoken lines—language shaped by emotion, timing, and voice—and wanted the
                        machine to read these scripts and transform them into a new form of language. However, many
                        dialogue-based APIs only provide raw text without clear attribution or citation, making them
                        difficult to reference responsibly.
                        <br><br>
                        As a result, the project shifted toward quoted language and adopted Quoteslate as an open,
                        publicly accessible API. This change preserved the original intention of working with authored,
                        expressive language while allowing the system to clearly acknowledge its sources. Quotes became
                        both a practical dataset and a conceptual bridge between human expression and algorithmic
                        recomposition.
                    </p>

                    <pre class="code-block"><code>
let order = 3;          
let ngrams = {};        
let sourceCount = 0;  
</code></pre>

                    <p class="p">

                        The system begins by defining the structure of the generator as a character-level 3-gram model
                        and initializing a data structure to store the statistical relationships between character
                        sequences and their possible continuations.
                    </p>

                    <pre class="code-block"><code>
const QUOTES_URL =
  'https://quoteslate.vercel.app/api/quotes/random?count=50&minLength=40';
</code></pre>

                    <pre class="code-block"><code>
const res = await fetch(QUOTES_URL);
const quotes = await res.json();
</code></pre>

                    <p class="p">

                        This step is critical because it treats language as raw material rather than a finished outcome.
                        By setting parameters such as count and minLength, the system controls the quality and density
                        of the dataset, ensuring that the source text is substantial enough to produce meaningful n-gram
                        relationships.
                    </p>

                    <pre class="code-block"><code>
let lineRaw = item.quote;
if (!exampleQuoteRaw) {
  exampleQuoteRaw = lineRaw.trim();
}
</code></pre>

                    <pre class="code-block"><code>
let line = lineRaw.replace(/[-"'`,!?;.:]/g, '').trim();
</code></pre>

                    <p class="p">
                        The system separates the text into two parallel pipelines: one for display and citation, and one
                        for computation. The cleaning step removes punctuation and contextual nuance in order to produce
                        a more stable, controllable statistical structure, similar to the preprocessing stage where
                        language models convert text into tokens.
                    </p>

                    <pre class="code-block"><code>
for (let i = 0; i <= line.length - order; i++) {
  const gram = line.substring(i, i + order);
  const nextChar = line.charAt(i + order);

  if (!ngrams[gram]) ngrams[gram] = [];
  ngrams[gram].push(nextChar);
}
</code></pre>

                    <p class="p">
                        This step functions as the training phase of the system, constructed in real time rather than
                        through offline learning. By allowing each n-gram to map to multiple possible next characters
                        (ngrams[gram].push(nextChar)), the model builds a probabilistic space from which outcomes can be
                        randomly sampled during generation.
                    </p>

                    <pre class="code-block"><code>
inputText.disabled = true;
generateButton.disabled = true;
useSeedButton.disabled = true;
</code></pre>

                    <pre class="code-block"><code>
inputText.disabled = false;
generateButton.disabled = false;
useSeedButton.disabled = false;
</code></pre>

                    <p class="p">
                        It enforces a clear procedural chain: Fetch → Build → Seed → Generate. By structuring the
                        interaction this way, the system makes it evident that the machine must first be fed with data
                        before it can produce language.
                    </p>

                    <pre class="code-block"><code>
const desiredLength = 30;
const seedLength = Math.min(exampleQuoteClean.length, desiredLength);
const seed = exampleQuoteClean.slice(0, seedLength);
inputText.value = seed;
</code></pre>

                    <p class="p">
                        The seed functions as a minimal prototype of a prompt at the character level. By using the
                        opening fragment of a quote as the seed, the generated text is more likely to inherit the
                        stylistic patterns of the source corpus.
                    </p>

                    <pre class="code-block"><code>
let currentGram = seed.substring(0, order);
let result = currentGram;

for (let i = 0; i < 150; i++) {
  const possibilities = ngrams[currentGram];
  if (!possibilities || possibilities.length === 0) break;

  const next =
    possibilities[Math.floor(Math.random() * possibilities.length)];
  result += next;

  currentGram = result.substring(result.length - order);
}
</code></pre>

                    <p class="p">
                        The random selection of the next character from multiple possible continuations
                        (possibilities[Math.floor(Math.random() * possibilities.length)]) forms the core of the
                        generative process, allowing the text to branch in unpredictable directions. The break condition
                        is equally important: when no valid continuation exists, the generation stops, revealing the
                        model’s limits and reinforcing its mechanical character.
                    </p>

                    <pre class="code-block"><code>
outputText.textContent =
  `Seed: “${seed}”\n\n` +
  `Mutated quote:\n${result}`;
</code></pre>

                    <p class="p">
                        This presentation makes clear that the generated text is not created from nothing, but emerges
                        through mutation and recombination of the source material, reinforcing the project’s conceptual
                        progression from citation to mutation to an algorithmic voice.
                    </p>

                    <figure class="figure">
                        <img src="04/1.png" alt="System diagram">
                    </figure>

                    <figure class="figure">
                        <img src="04/2.png" alt="System diagram">
                    </figure>

                </section>

                <!-- Result -->
                <section class="section" id="result">
                    <h2 class="h2">Result</h2>
                    <p class="p">
                        The final outcome of the project is a functioning, browser-based language generator that
                        produces mutated quotes through a simple character-level n-gram model. Using publicly sourced
                        quotes as its corpus, the system generates text that resembles human language in rhythm and
                        structure while remaining visibly synthetic in logic and tone.
                        <br><br>
                        Rather than producing coherent meaning, the generated output exposes patterns, repetitions, and
                        breakdowns within language itself. Each result reflects a hybrid authorship: fragments of human
                        expression recombined through algorithmic decision-making. The system’s limitations—such as
                        abrupt endings or repetitive sequences—are not treated as errors, but as evidence of the model’s
                        underlying mechanics.
                        <br><br>
                        Overall, the project succeeds in demonstrating how language can be abstracted, modeled, and
                        reassembled through procedural rules. The resulting texts operate as misquotes: neither faithful
                        citations nor fully original writing, but algorithmic voices shaped by probability, constraint,
                        and transformation.
                    </p>

                    <figure class="figure">
                        <iframe src="https://www.youtube.com/embed/k-j6DQa_15A" title="Text as material and artifact project"
                            allowfullscreen>
                        </iframe>


            </main>
        </div>

        <footer class="footer">
            <div>© <span id="year"></span> Creative Technology 03</div>
            <div>“Thank you Maxim”</div>
        </footer>
    </div>

    <script>
        document.getElementById('studentName').textContent = 'Yiqi Zhang';
        document.getElementById('year').textContent = new Date().getFullYear();

        // 可选：给目录点击增加平滑滚动（浏览器支持时生效）
        document.documentElement.style.scrollBehavior = 'smooth';
    </script>
</body>

</html>